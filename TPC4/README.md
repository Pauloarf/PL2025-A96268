# Manifesto TPC2

## üìå Informa√ß√£o do TPC e do Aluno  

- **T√≠tulo:** Analisador L√©xico
- **Data:** 2025/03/04
- **Autor:**  
    <table>
    <tr>
        <td><img src="../Images/Profile.jpg" width="100"></td>
        <td>
        <strong>Nome:</strong> Paulo Alexandre Rodrigues Ferreira<br>
        <strong>N√∫mero:</strong> A96268
        </td>
    </tr>
    </table>

**Resumo:** 

Com a realiza√ß√£o deste trabalho pretende-se construir um analisador l√©xico para uma linguagem de query com a qual se podem escrever frases do g√©nero:

```sparql
# DBPedia: obras de Chuck Berry  
select ?nome ?desc where {  
  ?s a dbo:MusicalArtists.  
  ?s foaf:name "Chuck Berry"@en .  
  ?w dbo:artist ?s.  
  ?w foaf:name ?nome.  
  ?w dbo:abstract ?desc  
} LIMIT 1000
```
Aqui est√° o conte√∫do formatado em Markdown (`.md`). Para evitar quebra de mensagens, o c√≥digo foi encapsulado com ` (crases simples) quando necess√°rio.

---

## üìÇ Resultados

O primeiro passo de desenvolvimento foi compreender o formato da linguagem a ser analisada. Isso √© essencial para identificar os elementos (tokens) que comp√µem a linguagem e definir como devem ser tratados.

Ap√≥s analisar o excerto fornecido e realizar pesquisas adicionais, concluiu-se que a linguagem de query em quest√£o √© semelhante (ou id√™ntica) ao SPARQL. Com base nisso, os principais elementos (tokens) a serem reconhecidos foram identificados como sendo:

- **Palavras-Chave**: `SELECT`, `WHERE`, `LIMIT`.
- **Vari√°veis**: `?nome`, `?desc`, `?s`, `?w`.
- **Strings**: `"Chuck Berry"@en`.
- **Identificadores (URIs)**: `dbo:MusicalArtists`, `foaf:name`, `dbo:artist`, `dbo:abstract`.
- **S√≠mbolos Especiais**: `{`, `}`, `.`, `a`.

O segundo passo consistiu em definir express√µes regulares para reconhecer cada tipo de token. Ap√≥s testes e valida√ß√µes utilizando ferramentas como o [regex101](https://regex101.com/), foram definidas as seguintes express√µes:

```python
tokens = [
    {"id": "SELECT", "expreg": r"SELECT"},  # Palavra-chave SELECT
    {"id": "WHERE", "expreg": r"WHERE"},    # Palavra-chave WHERE
    {"id": "LIMIT", "expreg": r"LIMIT"},    # Palavra-chave LIMIT
    {"id": "VARIABLE", "expreg": r"\?\w+"}, # Vari√°veis (come√ßam com ?)
    {"id": "STRING", "expreg": r'"[^"]+"@\w+'}, # Strings com idioma (ex: "Chuck Berry"@en)
    {"id": "URI", "expreg": r"\w+:\w+"},    # URIs (ex: dbo:MusicalArtists)
    {"id": "DOT", "expreg": r"\."},         # S√≠mbolo .
    {"id": "LBRACE", "expreg": r"\{"},      # S√≠mbolo {
    {"id": "RBRACE", "expreg": r"\}"},      # S√≠mbolo }
    {"id": "A", "expreg": r"a"},            # Palavra-chave 'a'
    {"id": "SKIP", "expreg": r"\s+"},       # Espa√ßos em branco (ignorar)
    {"id": "COMMENT", "expreg": r"#[^\n]*"}, # Coment√°rios (ignorar)
]
```

- Cada token possui um identificador `id` e uma express√£o regular `expreg` que define como ele √© reconhecido.

De seguida passou-se para o passo 3, onde o lexer foi constru√≠do utilizando as express√µes regulares definidas. Ele √© respons√°vel por percorrer o texto de entrada, reconhecer os tokens e retornar uma lista de tuplos contendo as informa√ß√µes de cada token.

O ultimo passou necess√°rio era testar o lexer, para isto foi utilizado o excerto fornecido.
A sa√≠da do lexer ser√° uma lista de tuplos no formato `(tipo_do_token, valor, linha, (in√≠cio, fim))`.

```
('SELECT', 'SELECT', 2, (1, 7))
('VARIABLE', '?nome', 2, (8, 13))
('VARIABLE', '?desc', 2, (14, 19))
('WHERE', 'WHERE', 2, (20, 25))
('LBRACE', '{', 2, (26, 27))
...
('LIMIT', 'LIMIT', 8, (182, 187))
```

Ap√≥s analisar o output, podemos concluir que o lexer aparenta ter sido implementado com sucesso, sendo capaz de reconhecer os tokens da linguagem.